{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62ed4664",
   "metadata": {},
   "source": [
    "\n",
    "# Challenge Problem 1 — Updated Plan Runner (Sergio)\n",
    "\n",
    "> **Note to self**: This notebook implements my **Updated Plan** for Challenge Problem 1 (2.155 ML & AI for Design Engineering @ MIT).\n",
    "> It follows the same code style and class usage from the starter and advanced notebooks:\n",
    "> - Set JAX to CPU, deterministic seeds\n",
    "> - Use `LINKS` modules: `MechanismVisualizer`, `MechanismSolver`, `CurveEngine`, `Tools`, `DifferentiableTools`\n",
    "> - Use `pymoo` with NSGA-II for GA\n",
    ">\n",
    "> **Outline**\n",
    "> 1. Environment Setup (imports, seeds, device)\n",
    "> 2. Load Resources (target curves, starter mechanism) + Visualize targets\n",
    "> 3. Helper Utilities (validation, random mechanism generation, diversity selection, HV greedy selection)\n",
    "> 4. **A — Bulk Seeding** (random valid mechanisms → preprocessed → valid bank per curve)\n",
    "> 5. **B1 — GA Track** (Starter positions-only / Advanced mixed-variable placeholder)\n",
    "> 6. **B2 — GD Refinement Track** (multi-objective GD on positions using both Distance & Material gradients)\n",
    "> 7. **C — Pool, De-duplicate & Select Top-1000** (diversity-aware + HV-greedy)\n",
    "> 8. Evaluation & Reporting (HV per curve, Pareto plots, alignment checks)\n",
    "> 9. Save Results & Submission Packaging\n",
    ">\n",
    "> **How to use**\n",
    "> - Run from top to bottom for each target curve (or loop over all 6).\n",
    "> - All hyperparameters are grouped in one place. Keep constraints **exactly** as in the starter/advanced notebooks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd49976c",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Environment Setup\n",
    "Make execution deterministic and import the same modules used in the provided notebooks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf37917",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ[\"JAX_PLATFORMS\"] = \"cpu\"  # Disable GPU for JAX (Remove if you want to use GPU)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from typing import Tuple, Dict, Any, List\n",
    "\n",
    "# deterministic random numbers\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "# LINKS modules (same as in the notebooks)\n",
    "from LINKS.Visualization import MechanismVisualizer\n",
    "from LINKS.Kinematics import MechanismSolver\n",
    "from LINKS.Geometry import CurveEngine\n",
    "from LINKS.Optimization import Tools, DifferentiableTools\n",
    "\n",
    "# pymoo for GA and HV\n",
    "from pymoo.core.problem import ElementwiseProblem\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.operators.sampling.rnd import FloatRandomSampling\n",
    "from pymoo.operators.crossover.sbx import SBX\n",
    "from pymoo.operators.mutation.pm import PolynomialMutation\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.indicators.hv import HV\n",
    "\n",
    "# Global configs\n",
    "DEVICE = 'cpu'  # 'cpu' or 'gpu' if available in your setup\n",
    "RUN_STAMP = \"{stamp}\".format(stamp=np.datetime64('now')).replace(\":\", \"-\")\n",
    "\n",
    "# Visualizer / Solver / Curve engine\n",
    "visualizer = MechanismVisualizer()\n",
    "solver = MechanismSolver(device=DEVICE)\n",
    "curve_processor = CurveEngine(normalize_scale=False, device=DEVICE)\n",
    "\n",
    "# Optimization tools\n",
    "optimization_tools = Tools(device=DEVICE)\n",
    "optimization_tools.compile()  # compile for speed\n",
    "gradient_tools = DifferentiableTools(device=DEVICE)\n",
    "gradient_tools.compile()      # compile for speed\n",
    "\n",
    "print(\"Setup complete. Device:\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd21831",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Load Resources & Visualize Target Curves\n",
    "`target_curves.npy` and `starter_mechanism.npy` are provided in the repository.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c7482c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load target curves\n",
    "target_curves = np.load('target_curves.npy')\n",
    "\n",
    "# Optional: Load starter mechanism (useful for positions-only GA seeding)\n",
    "try:\n",
    "    starter_mech = np.load('starter_mechanism.npy', allow_pickle=True).item()\n",
    "    print(\"Loaded starter_mechanism.npy\")\n",
    "except Exception as e:\n",
    "    starter_mech = None\n",
    "    print(\"Could not load starter_mechanism.npy:\", e)\n",
    "\n",
    "# Plot all target curves\n",
    "fig, axs = plt.subplots(2, 3, figsize=(8, 5))\n",
    "for i in range(6):\n",
    "    x_coords = np.array(target_curves[i])[:, 0]\n",
    "    y_coords = np.array(target_curves[i])[:, 1]\n",
    "    axs[i // 3, i % 3].plot(x_coords, y_coords, linewidth=3)\n",
    "    axs[i // 3, i % 3].set_title(f'Egg {i + 1}')\n",
    "    axs[i // 3, i % 3].axis('equal')\n",
    "    axs[i // 3, i % 3].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d15936",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Helper Utilities\n",
    "Validation helpers, random mechanism generation (fallback if no built-in randomizer), diversity selection, and HV-greedy selection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbf1d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Constraints (MUST MATCH notebooks)\n",
    "DISTANCE_MAX = 0.75\n",
    "MATERIAL_MAX = 10.0\n",
    "JOINTS_MAX = 20\n",
    "BOUNDS_L = 0.0\n",
    "BOUNDS_U = 5.0\n",
    "\n",
    "REF_POINT = np.array([DISTANCE_MAX, MATERIAL_MAX], dtype=float)\n",
    "\n",
    "def is_connected(edges: np.ndarray, N: int) -> bool:\n",
    "    \"\"\"Simple BFS connectivity over undirected graph.\"\"\"\n",
    "    if N == 0:\n",
    "        return False\n",
    "    adj = [[] for _ in range(N)]\n",
    "    for u, v in edges:\n",
    "        if u < 0 or v < 0 or u >= N or v >= N:\n",
    "            return False\n",
    "        adj[u].append(v)\n",
    "        adj[v].append(u)\n",
    "    seen = set([0])\n",
    "    stack = [0]\n",
    "    while stack:\n",
    "        u = stack.pop()\n",
    "        for w in adj[u]:\n",
    "            if w not in seen:\n",
    "                seen.add(w)\n",
    "                stack.append(w)\n",
    "    return len(seen) == N\n",
    "\n",
    "def validate_mechanism(x0: np.ndarray,\n",
    "                       edges: np.ndarray,\n",
    "                       fixed_joints: np.ndarray,\n",
    "                       motor: np.ndarray) -> bool:\n",
    "    \"\"\"Basic structural checks before simulation.\"\"\"\n",
    "    N = x0.shape[0]\n",
    "    if N > JOINTS_MAX:\n",
    "        return False\n",
    "    if edges.ndim != 2 or edges.shape[1] != 2:\n",
    "        return False\n",
    "    if not is_connected(edges, N):\n",
    "        return False\n",
    "    # Motor must reference a valid edge\n",
    "    a, b = int(motor[0]), int(motor[1])\n",
    "    if a < 0 or b < 0 or a >= N or b >= N:\n",
    "        return False\n",
    "    # Ensure undirected edge presence\n",
    "    if not any(((e[0] == a and e[1] == b) or (e[0] == b and e[1] == a)) for e in edges):\n",
    "        return False\n",
    "    # Fixed joints must be within range\n",
    "    if np.any(fixed_joints < 0) or np.any(fixed_joints >= N):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def eval_distance_material(x0: np.ndarray,\n",
    "                           edges: np.ndarray,\n",
    "                           fixed_joints: np.ndarray,\n",
    "                           motor: np.ndarray,\n",
    "                           target_curve: np.ndarray,\n",
    "                           target_idx=None):\n",
    "    \"\"\"Wrapper around Tools to get (distance, material).\"\"\"\n",
    "    d, m = optimization_tools(x0, edges, fixed_joints, motor, target_curve, target_idx=target_idx)\n",
    "    return float(d), float(m)\n",
    "\n",
    "def is_valid_objectives(distance: float, material: float) -> bool:\n",
    "    return (distance <= DISTANCE_MAX) and (material <= MATERIAL_MAX)\n",
    "\n",
    "def farthest_point_selection(points: np.ndarray, k: int) -> np.ndarray:\n",
    "    \"\"\"Farthest-point sampling in objective space to maximize spread.\n",
    "    points: (N, 2) for (distance, material).\n",
    "    Returns indices of selected points.\n",
    "    \"\"\"\n",
    "    n = points.shape[0]\n",
    "    if k >= n:\n",
    "        return np.arange(n)\n",
    "    # Normalize to [0,1] box using ref point as max\n",
    "    eps = 1e-12\n",
    "    norm = np.clip(points / (REF_POINT + eps), 0.0, 1.0)\n",
    "    # start with best distance+material sum\n",
    "    start = np.argmin(norm.sum(axis=1))\n",
    "    selected = [start]\n",
    "    remaining = set(range(n)) - set(selected)\n",
    "    dist_cache = np.linalg.norm(norm - norm[start], axis=1)\n",
    "    while len(selected) < k and remaining:\n",
    "        # pick point that maximizes min distance to selected\n",
    "        min_d = np.min(np.vstack([np.linalg.norm(norm - norm[idx], axis=1) for idx in selected]), axis=0)\n",
    "        min_d[list(selected)] = -1.0\n",
    "        nxt = int(np.argmax(min_d))\n",
    "        selected.append(nxt)\n",
    "        remaining.discard(nxt)\n",
    "    return np.array(selected, dtype=int)\n",
    "\n",
    "def hv_greedy_selection(points: np.ndarray, k: int, ref_point: np.ndarray = REF_POINT) -> np.ndarray:\n",
    "    \"\"\"Greedy HV selection from a set of 2D points (minimization objectives).\n",
    "    points: (N,2) objective values\n",
    "    Returns indices of selected points (size <= k).\n",
    "    \"\"\"\n",
    "    hv = HV(ref_point=ref_point)\n",
    "    n = points.shape[0]\n",
    "    if k >= n:\n",
    "        return np.arange(n)\n",
    "    selected = []\n",
    "    best_set = np.empty((0, 2), dtype=float)\n",
    "    remaining = list(range(n))\n",
    "    # seed: point with best HV alone\n",
    "    gains = []\n",
    "    for idx in remaining:\n",
    "        g = hv(np.array([points[idx]], dtype=float))\n",
    "        gains.append((g, idx))\n",
    "    gains.sort(reverse=True, key=lambda t: t[0])\n",
    "    selected.append(gains[0][1])\n",
    "    best_set = np.vstack([best_set, points[selected[-1]]])\n",
    "    remaining.remove(selected[-1])\n",
    "\n",
    "    # add greedily\n",
    "    while len(selected) < k and remaining:\n",
    "        best_gain = -np.inf\n",
    "        best_idx = None\n",
    "        current_hv = hv(best_set)\n",
    "        for idx in remaining:\n",
    "            cand_set = np.vstack([best_set, points[idx]])\n",
    "            gain = hv(cand_set) - current_hv\n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                best_idx = idx\n",
    "        if best_idx is None:\n",
    "            break\n",
    "        selected.append(best_idx)\n",
    "        best_set = np.vstack([best_set, points[best_idx]])\n",
    "        remaining.remove(best_idx)\n",
    "\n",
    "    return np.array(selected, dtype=int)\n",
    "\n",
    "def deduplicate_by_objectives(points: np.ndarray, tol: float = 1e-4) -> np.ndarray:\n",
    "    \"\"\"Remove near-duplicate objective points (distance, material) within tol.\n",
    "    Returns indices to keep.\n",
    "    \"\"\"\n",
    "    keep = []\n",
    "    used = np.zeros(points.shape[0], dtype=bool)\n",
    "    for i in range(points.shape[0]):\n",
    "        if used[i]:\n",
    "            continue\n",
    "        keep.append(i)\n",
    "        di = np.abs(points - points[i])\n",
    "        used |= (di[:,0] <= tol) & (di[:,1] <= tol)\n",
    "    return np.array(keep, dtype=int)\n",
    "\n",
    "def pack_mechanism(x0, edges, fixed_joints, motor, target_idx=None) -> Dict[str, Any]:\n",
    "    mech = {\n",
    "        \"x0\": np.array(x0, dtype=float),\n",
    "        \"edges\": np.array(edges, dtype=int),\n",
    "        \"fixed_joints\": np.array(fixed_joints, dtype=int),\n",
    "        \"motor\": np.array(motor, dtype=int),\n",
    "    }\n",
    "    if target_idx is not None:\n",
    "        mech[\"target_idx\"] = int(target_idx)\n",
    "    return mech\n",
    "\n",
    "# --- Random mechanism generation (fallback) ---\n",
    "def random_connectivity_upper_tri(N: int, edge_prob: float = 0.25) -> np.ndarray:\n",
    "    \"\"\"Generate a symmetric 0/1 connectivity matrix with zero diagonal (upper-tri sampling).\"\"\"\n",
    "    C = np.zeros((N, N), dtype=int)\n",
    "    for i in range(N):\n",
    "        for j in range(i+1, N):\n",
    "            C[i, j] = 1 if (random.random() < edge_prob) else 0\n",
    "    C = C + C.T\n",
    "    np.fill_diagonal(C, 0)\n",
    "    # ensure at least a simple spanning backbone\n",
    "    for i in range(1, N):\n",
    "        C[i-1, i] = 1\n",
    "        C[i, i-1] = 1\n",
    "    return C\n",
    "\n",
    "def edges_from_connectivity(C: np.ndarray) -> np.ndarray:\n",
    "    es = []\n",
    "    N = C.shape[0]\n",
    "    for i in range(N):\n",
    "        for j in range(i+1, N):\n",
    "            if C[i, j] == 1:\n",
    "                es.append([i, j])\n",
    "    return np.array(es, dtype=int)\n",
    "\n",
    "def sample_random_mechanism(N: int,\n",
    "                            bounds: Tuple[float, float] = (BOUNDS_L, BOUNDS_U),\n",
    "                            edge_prob: float = 0.25,\n",
    "                            fixed_mode: str = \"two_left\",\n",
    "                            motor_pair: Tuple[int, int] = (0, 2)) -> Dict[str, Any]:\n",
    "    \"\"\"Fallback: generate a random mechanism with N nodes.\n",
    "    - Positions uniform in [L, U]\n",
    "    - Connectivity via symmetric upper-tri matrix + backbone\n",
    "    - Two fixed joints by default at indices 0 and 1\n",
    "    - Motor defaults to (0,2), which is usually an existing edge due to backbone\n",
    "    \"\"\"\n",
    "    L, U = bounds\n",
    "    x0 = np.random.uniform(L + 0.1, U - 0.1, size=(N, 2))\n",
    "    C = random_connectivity_upper_tri(N, edge_prob=edge_prob)\n",
    "    edges = edges_from_connectivity(C)\n",
    "\n",
    "    if fixed_mode == \"two_left\":\n",
    "        fixed_joints = np.array([0, 1], dtype=int)\n",
    "    else:\n",
    "        fixed_joints = np.array(sorted(random.sample(range(N), k=2)), dtype=int)\n",
    "\n",
    "    motor = np.array(list(motor_pair), dtype=int)\n",
    "    mech = pack_mechanism(x0, edges, fixed_joints, motor, target_idx=None)\n",
    "    return mech\n",
    "\n",
    "print(\"Utilities ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2aa4da9",
   "metadata": {},
   "source": [
    "\n",
    "## 4) A — Bulk Seeding (diverse, valid starts)\n",
    "Generate a large pool of random mechanisms for a chosen target curve, evaluate, and keep only valid ones.\n",
    "We also apply basic preprocessing (connectivity check, coarse filtering, duplicate culling).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b745bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Hyperparameters (edit here) ===\n",
    "TARGET_INDICES = list(range(6))      # run for all curves by default\n",
    "POOL_PER_CURVE = 5000                # e.g., 5k–10k\n",
    "N_RANGE = [7, 8, 9, 10, 12, 14]      # mechanism sizes to sample\n",
    "EDGE_PROB = 0.25\n",
    "MAX_SEED_EVAL = POOL_PER_CURVE       # cap evaluations for speed if needed\n",
    "DUP_TOL = 1e-4\n",
    "\n",
    "# Storage\n",
    "seed_banks = {ti: [] for ti in TARGET_INDICES}\n",
    "seed_objectives = {ti: [] for ti in TARGET_INDICES}\n",
    "\n",
    "for ti in TARGET_INDICES:\n",
    "    target_curve = np.array(target_curves[ti])\n",
    "    kept = 0\n",
    "    tried = 0\n",
    "\n",
    "    while kept < POOL_PER_CURVE and tried < MAX_SEED_EVAL * 10:\n",
    "        tried += 1\n",
    "        N = random.choice(N_RANGE)\n",
    "        mech = sample_random_mechanism(N=N, edge_prob=EDGE_PROB)\n",
    "        x0 = mech['x0']; edges = mech['edges']; fixed_joints = mech['fixed_joints']; motor = mech['motor']\n",
    "\n",
    "        # Structural validation\n",
    "        if not validate_mechanism(x0, edges, fixed_joints, motor):\n",
    "            continue\n",
    "\n",
    "        # Evaluate (distance, material)\n",
    "        d, m = eval_distance_material(x0, edges, fixed_joints, motor, target_curve, target_idx=None)\n",
    "\n",
    "        # Keep only valid per constraints\n",
    "        if is_valid_objectives(d, m):\n",
    "            seed_banks[ti].append(mech)\n",
    "            seed_objectives[ti].append([d, m])\n",
    "            kept += 1\n",
    "\n",
    "        if kept % 200 == 0 and kept > 0:\n",
    "            print(f\"[Curve {ti+1}] Valid seeds kept: {kept}/{POOL_PER_CURVE}\")\n",
    "\n",
    "    seed_objectives[ti] = np.array(seed_objectives[ti], dtype=float)\n",
    "    print(f\"[Curve {ti+1}] Final valid seeds: {len(seed_banks[ti])}\")\n",
    "    \n",
    "    # De-duplicate near-identical objective points\n",
    "    if len(seed_banks[ti]) > 0:\n",
    "        keep_idx = deduplicate_by_objectives(seed_objectives[ti], tol=DUP_TOL)\n",
    "        seed_banks[ti] = [seed_banks[ti][k] for k in keep_idx]\n",
    "        seed_objectives[ti] = seed_objectives[ti][keep_idx]\n",
    "        print(f\"[Curve {ti+1}] After dedup: {len(seed_banks[ti])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbf511f",
   "metadata": {},
   "source": [
    "\n",
    "## 5) B1 — GA Track\n",
    "Two flavors:\n",
    "- **Starter (positions-only):** optimize node positions for a fixed skeleton (uses `ElementwiseProblem` exactly like the starter notebook).\n",
    "- **Advanced (mixed-variable):** positions + connectivity (placeholder here; use Advanced Starter code to define the mixed-variable problem).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c9aae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === GA hyperparameters (edit here) ===\n",
    "POP_SIZE = 100\n",
    "N_GEN = 100\n",
    "SBX_ETA = 3.0\n",
    "SBX_PROB = 1.0\n",
    "PM_ETA = 3.0\n",
    "PM_PROB = 0.05\n",
    "\n",
    "ga_elites = {ti: [] for ti in TARGET_INDICES}\n",
    "ga_elites_obj = {ti: [] for ti in TARGET_INDICES}\n",
    "\n",
    "class MechanismSynthesisPositionsOnly(ElementwiseProblem):\n",
    "    \"\"\"Positions-only GA (Starter-style), constraints exactly as in the starter notebook.\"\"\"\n",
    "    def __init__(self, edges, fixed_joints, motor, target_curve, N_nodes):\n",
    "        super().__init__(n_var=N_nodes*2, n_obj=2, n_constr=2, xl=BOUNDS_L, xu=BOUNDS_U, elementwise_evaluation=True)\n",
    "        self.edges = edges\n",
    "        self.fixed_joints = fixed_joints\n",
    "        self.motor = motor\n",
    "        self.target_curve = target_curve\n",
    "        self.N = N_nodes\n",
    "\n",
    "    def _evaluate(self, x, out, *args, **kwargs):\n",
    "        x0 = np.array(x).reshape(self.N, 2)\n",
    "        d, m = optimization_tools(x0, self.edges, self.fixed_joints, self.motor, self.target_curve, target_idx=None)\n",
    "        out[\"F\"] = np.array([d, m], dtype=float)\n",
    "        out[\"G\"] = out[\"F\"] - np.array([DISTANCE_MAX, MATERIAL_MAX], dtype=float)\n",
    "\n",
    "def run_positions_only_ga_for_curve(target_idx: int,\n",
    "                                    base_mech: Dict[str, Any],\n",
    "                                    pop_size: int = POP_SIZE,\n",
    "                                    n_gen: int = N_GEN) -> Tuple[List[Dict[str, Any]], np.ndarray]:\n",
    "    \"\"\"Run Starter-style GA using the starter skeleton; initialize with duplicated x0 population.\"\"\"\n",
    "    edges = base_mech['edges']\n",
    "    fixed_joints = base_mech['fixed_joints']\n",
    "    motor = base_mech['motor']\n",
    "    x0 = base_mech['x0']\n",
    "    N_nodes = x0.shape[0]\n",
    "    target_curve = np.array(target_curves[target_idx])\n",
    "\n",
    "    problem = MechanismSynthesisPositionsOnly(edges, fixed_joints, motor, target_curve, N_nodes=N_nodes)\n",
    "\n",
    "    # Initialize a population of duplicates (as per starter notebook)\n",
    "    X = x0[None].repeat(pop_size, axis=0).reshape(pop_size, -1)\n",
    "\n",
    "    algorithm = NSGA2(pop_size=pop_size,\n",
    "                      sampling=X,\n",
    "                      crossover=SBX(prob=SBX_PROB, eta=SBX_ETA),\n",
    "                      mutation=PolynomialMutation(eta=PM_ETA, prob=PM_PROB),\n",
    "                      eliminate_duplicates=True)\n",
    "\n",
    "    res = minimize(problem,\n",
    "                   algorithm,\n",
    "                   ('n_gen', n_gen),\n",
    "                   verbose=True,\n",
    "                   save_history=False,\n",
    "                   seed=0)\n",
    "\n",
    "    # Extract valid solutions\n",
    "    Xsol = res.X if res.X is not None else np.empty((0, N_nodes*2))\n",
    "    Fsol = res.F if res.F is not None else np.empty((0, 2))\n",
    "    valid_idx = np.where((Fsol[:,0] <= DISTANCE_MAX) & (Fsol[:,1] <= MATERIAL_MAX))[0]\n",
    "\n",
    "    elites = []\n",
    "    for idx in valid_idx:\n",
    "        x0_sol = Xsol[idx].reshape(N_nodes, 2)\n",
    "        elites.append(pack_mechanism(x0_sol, edges, fixed_joints, motor, target_idx=None))\n",
    "    return elites, Fsol[valid_idx]\n",
    "\n",
    "# --- Run positions-only GA per curve (using starter mechanism if available) ---\n",
    "for ti in TARGET_INDICES:\n",
    "    print(f\"\"\"\\n=== GA (positions-only) for Curve {ti+1} ===\"\"\")\n",
    "    if starter_mech is None:\n",
    "        print(\"No starter_mechanism.npy available; skipping positions-only GA for this curve.\")\n",
    "        continue\n",
    "    elites, F = run_positions_only_ga_for_curve(ti, starter_mech, pop_size=POP_SIZE, n_gen=N_GEN)\n",
    "    ga_elites[ti].extend(elites)\n",
    "    ga_elites_obj[ti].extend(F.tolist())\n",
    "    print(f\"Curve {ti+1}: GA valid elites collected = {len(elites)}\")\n",
    "\n",
    "# --- Placeholder: Advanced mixed-variable GA (positions + connectivity) ---\n",
    "# NOTE: Use the Advanced Starter Notebook's mixed-variable problem class here if desired.\n",
    "# After running, extend ga_elites[ti] and ga_elites_obj[ti] with additional valid elites.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9d95ae",
   "metadata": {},
   "source": [
    "\n",
    "## 6) B2 — GD Refinement Track (multi-objective on positions)\n",
    "Refine GA elites by running gradient-based optimization on **positions** using `DifferentiableTools`.\n",
    "We use both **Distance** and **Material** gradients via scalarization with rotating weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fd67ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === GD hyperparameters (edit here) ===\n",
    "GD_ITERS = 50\n",
    "GD_STEP = 0.01\n",
    "SCALAR_WEIGHTS = [0.2, 0.5, 0.8]  # rotate these to emphasize Distance vs Material\n",
    "\n",
    "gd_refined = {ti: [] for ti in TARGET_INDICES}\n",
    "gd_refined_obj = {ti: [] for ti in TARGET_INDICES}\n",
    "\n",
    "def project_positions(x0: np.ndarray, lo=BOUNDS_L, hi=BOUNDS_U) -> np.ndarray:\n",
    "    return np.clip(x0, lo, hi)\n",
    "\n",
    "def gd_refine_positions(mech: Dict[str, Any], target_curve: np.ndarray) -> Tuple[Dict[str, Any], Tuple[float, float]]:\n",
    "    x0 = mech['x0'].copy()\n",
    "    edges = mech['edges']\n",
    "    fixed_joints = mech['fixed_joints']\n",
    "    motor = mech['motor']\n",
    "\n",
    "    # Multi-objective via scalarization loop\n",
    "    for it in range(GD_ITERS):\n",
    "        w = SCALAR_WEIGHTS[it % len(SCALAR_WEIGHTS)]\n",
    "        d, m, d_grad_list, m_grad_list = gradient_tools(x0, edges, fixed_joints, motor, target_curve, target_idx=None)\n",
    "        # grads come as a list of arrays per-node; stack to shape (N,2)\n",
    "        dG = np.stack(d_grad_list, axis=0)\n",
    "        mG = np.stack(m_grad_list, axis=0)\n",
    "        grad = w * dG + (1.0 - w) * mG\n",
    "\n",
    "        # freeze fixed joints\n",
    "        mask = np.ones_like(x0, dtype=bool)\n",
    "        mask[fixed_joints] = False\n",
    "\n",
    "        # gradient descent step\n",
    "        x0[mask] = x0[mask] - GD_STEP * grad[mask]\n",
    "\n",
    "        # project back to bounds\n",
    "        x0 = project_positions(x0)\n",
    "\n",
    "    # final evaluation\n",
    "    d, m = eval_distance_material(x0, edges, fixed_joints, motor, target_curve, target_idx=None)\n",
    "    refined = pack_mechanism(x0, edges, fixed_joints, motor, target_idx=None)\n",
    "    return refined, (d, m)\n",
    "\n",
    "# Run GD refinement on top GA elites\n",
    "for ti in TARGET_INDICES:\n",
    "    target_curve = np.array(target_curves[ti])\n",
    "    elites = ga_elites[ti]\n",
    "    if len(elites) == 0:\n",
    "        print(f\"Curve {ti+1}: No GA elites to refine.\")\n",
    "        continue\n",
    "    for mech in elites:\n",
    "        refined, (d, m) = gd_refine_positions(mech, target_curve)\n",
    "        if is_valid_objectives(d, m):\n",
    "            gd_refined[ti].append(refined)\n",
    "            gd_refined_obj[ti].append([d, m])\n",
    "    print(f\"Curve {ti+1}: GD refined valid = {len(gd_refined[ti])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903f4ad2",
   "metadata": {},
   "source": [
    "\n",
    "## 7) C — Pool, De-duplicate & Select Top-1000 (per curve)\n",
    "Combine seed bank + GA elites + GD refined; remove duplicates; select **top-1000** via diversity-aware + HV-greedy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffc890c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TOP_K_SUBMIT = 1000\n",
    "\n",
    "selected_per_curve = {}\n",
    "selected_obj_per_curve = {}\n",
    "\n",
    "for ti in TARGET_INDICES:\n",
    "    objs = []\n",
    "    mechs = []\n",
    "\n",
    "    # Seeds\n",
    "    if ti in seed_banks:\n",
    "        for mech, (d, m) in zip(seed_banks[ti], seed_objectives[ti] if len(seed_objectives[ti])>0 else []):\n",
    "            mechs.append(mech)\n",
    "            objs.append([d, m])\n",
    "\n",
    "    # GA elites\n",
    "    for mech, (d, m) in zip(ga_elites[ti], ga_elites_obj[ti] if len(ga_elites_obj[ti])>0 else []):\n",
    "        mechs.append(mech)\n",
    "        objs.append([d, m])\n",
    "\n",
    "    # GD refined\n",
    "    for mech, (d, m) in zip(gd_refined[ti], gd_refined_obj[ti] if len(gd_refined_obj[ti])>0 else []):\n",
    "        mechs.append(mech)\n",
    "        objs.append([d, m])\n",
    "\n",
    "    if len(mechs) == 0:\n",
    "        print(f\"Curve {ti+1}: No candidates to select from.\")\n",
    "        selected_per_curve[ti] = []\n",
    "        selected_obj_per_curve[ti] = np.empty((0,2))\n",
    "        continue\n",
    "\n",
    "    objs = np.array(objs, dtype=float)\n",
    "\n",
    "    # De-duplicate near-identical objective points\n",
    "    keep_idx = deduplicate_by_objectives(objs, tol=1e-5)\n",
    "    objs = objs[keep_idx]\n",
    "    mechs = [mechs[i] for i in keep_idx]\n",
    "\n",
    "    # Diversity-aware pruning to (at most) 2*TOP_K_SUBMIT to keep HV greedy fast\n",
    "    if len(mechs) > 2*TOP_K_SUBMIT:\n",
    "        idx_div = farthest_point_selection(objs, k=2*TOP_K_SUBMIT)\n",
    "        objs = objs[idx_div]\n",
    "        mechs = [mechs[i] for i in idx_div]\n",
    "\n",
    "    # HV-greedy selection to TOP_K_SUBMIT\n",
    "    sel_idx = hv_greedy_selection(objs, k=min(TOP_K_SUBMIT, len(mechs)), ref_point=REF_POINT)\n",
    "    selected_per_curve[ti] = [mechs[i] for i in sel_idx]\n",
    "    selected_obj_per_curve[ti] = objs[sel_idx]\n",
    "\n",
    "    print(f\"Curve {ti+1}: Selected {len(selected_per_curve[ti])} for submission (of {len(mechs)} candidates).\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcd061c",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Evaluation & Reporting\n",
    "Quick hypervolume (HV) summary per curve and Pareto scatter plots; also optional alignment checks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905301ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# HV per curve\n",
    "hv_indicator = HV(ref_point=REF_POINT)\n",
    "hv_scores = {}\n",
    "\n",
    "for ti in TARGET_INDICES:\n",
    "    F = selected_obj_per_curve.get(ti, np.empty((0,2)))\n",
    "    if F.shape[0] == 0:\n",
    "        hv_scores[ti] = 0.0\n",
    "    else:\n",
    "        hv_scores[ti] = float(hv_indicator(F))\n",
    "\n",
    "print(\"Hypervolume per curve (ref point {}):\".format(REF_POINT.tolist()))\n",
    "for ti in TARGET_INDICES:\n",
    "    print(f\"  Curve {ti+1}: HV = {hv_scores[ti]:.6f} (count={selected_obj_per_curve.get(ti, np.empty((0,2))).shape[0]})\")\n",
    "\n",
    "# Scatter plots of Pareto points\n",
    "cols = 3\n",
    "rows = int(np.ceil(len(TARGET_INDICES) / cols))\n",
    "plt.figure(figsize=(cols*4, rows*3.5))\n",
    "for idx, ti in enumerate(TARGET_INDICES):\n",
    "    plt.subplot(rows, cols, idx+1)\n",
    "    F = selected_obj_per_curve.get(ti, np.empty((0,2)))\n",
    "    if F.shape[0] > 0:\n",
    "        plt.scatter(F[:,0], F[:,1], s=10)\n",
    "    plt.axvline(DISTANCE_MAX, linestyle='--', linewidth=1)\n",
    "    plt.axhline(MATERIAL_MAX, linestyle='--', linewidth=1)\n",
    "    plt.title(f'Curve {ti+1} (n={F.shape[0]})')\n",
    "    plt.xlabel('Distance')\n",
    "    plt.ylabel('Material')\n",
    "    plt.gca().invert_xaxis()  # sometimes helpful to visualize \"better\" to the right\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Optional: visualize alignment for a few selected mechanisms per curve\n",
    "EXAMPLES_PER_CURVE = 3\n",
    "for ti in TARGET_INDICES:\n",
    "    target_curve = np.array(target_curves[ti])\n",
    "    picks = selected_per_curve[ti][:EXAMPLES_PER_CURVE]\n",
    "    print(f\"\\nCurve {ti+1} — visual checks for {len(picks)} examples:\")\n",
    "    for mech in picks:\n",
    "        # Solve and visualize traced curve of the last joint by default\n",
    "        sol = solver(mech['x0'], mech['edges'], mech['fixed_joints'], mech['motor'])\n",
    "        traced_curve = sol[-1]  # default: last joint as \"most complex\"\n",
    "        curve_processor.visualize_alignment(traced_curve, target_curve)\n",
    "        curve_processor.visualize_comparison(traced_curve, target_curve)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad2b638",
   "metadata": {},
   "source": [
    "\n",
    "## 9) Save Results & Submission Packaging\n",
    "Save:\n",
    "- Per-curve selected mechanisms (structures + positions)\n",
    "- Objectives for quick reference\n",
    "- A single `submission` object stub you can adapt to the course's `evaluate_submission` helper.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae687ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pathlib, json\n",
    "\n",
    "outdir = pathlib.Path(f\"results_{RUN_STAMP}\")\n",
    "outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save per-curve mechanisms and objectives\n",
    "for ti in TARGET_INDICES:\n",
    "    mechs = selected_per_curve.get(ti, [])\n",
    "    F = selected_obj_per_curve.get(ti, np.empty((0,2)))\n",
    "    np.save(outdir / f\"curve_{ti+1}_mechanisms.npy\", np.array(mechs, dtype=object))\n",
    "    np.save(outdir / f\"curve_{ti+1}_objectives.npy\", F)\n",
    "print(\"Saved per-curve mechanism and objective arrays.\")\n",
    "\n",
    "# Build a submission stub (adjust keys to match the grader's expected format)\n",
    "# Here we follow a simple structure: a dict mapping curve index -> list of mechanism dicts\n",
    "submission = {f\"curve_{ti+1}\": selected_per_curve.get(ti, []) for ti in TARGET_INDICES}\n",
    "\n",
    "# Save JSON (positions/arrays converted to lists for portability)\n",
    "def jsonify_mech(m):\n",
    "    return {\n",
    "        \"x0\": m[\"x0\"].tolist(),\n",
    "        \"edges\": m[\"edges\"].tolist(),\n",
    "        \"fixed_joints\": m[\"fixed_joints\"].tolist(),\n",
    "        \"motor\": m[\"motor\"].tolist(),\n",
    "        **({\"target_idx\": int(m.get(\"target_idx\"))} if (\"target_idx\" in m) else {})\n",
    "    }\n",
    "\n",
    "submission_json = {k: [jsonify_mech(m) for m in v] for k, v in submission.items()}\n",
    "with open(outdir / \"submission.json\", \"w\") as f:\n",
    "    json.dump(submission_json, f)\n",
    "\n",
    "# Also save a numpy version if preferred by grader utilities\n",
    "np.save(outdir / \"submission.npy\", np.array(submission, dtype=object))\n",
    "\n",
    "print(\"Saved submission to:\", outdir)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
